{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b85fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "Macro F1 = 0.2650\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Macro F1 = 0.3468\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Macro F1 = 0.1883\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Macro F1 = 0.2225\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Macro F1 = 0.2626\n",
      "\n",
      "Average Macro F1 Across Folds: 0.2570221218111244\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "# 1. LOAD CORPUS (word/tag word/tag ...)\n",
    "\n",
    "def load_tagged_corpus(path=\"wsj_pos_tagged_en.txt\"):\n",
    "    sentences = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            sent = []\n",
    "            for token in line.split():\n",
    "                if \"/\" not in token:\n",
    "                    continue\n",
    "                word, tag = token.rsplit(\"/\", 1)\n",
    "                sent.append((word, tag))\n",
    "\n",
    "            if sent:\n",
    "                sentences.append(sent)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 2. K-FOLD SPLIT\n",
    "def k_fold_split(data, k=5, seed=42):\n",
    "    random.Random(seed).shuffle(data)\n",
    "    n = len(data)\n",
    "    fold_size = n // k\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i < k - 1 else n\n",
    "        folds.append(data[start:end])\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "# 3. HMM TRAINING (EMISSION + TRANSITION)\n",
    "class HMMTagger:\n",
    "    def __init__(self, smoothing=1.0):\n",
    "        self.smoothing = smoothing\n",
    "        self.tags = set()\n",
    "        self.words = set()\n",
    "        self.start_symbol = \"<s>\"\n",
    "        self.unk = \"<UNK>\"\n",
    "\n",
    "        self.tag_counts = Counter()\n",
    "        self.emission_counts = defaultdict(Counter)\n",
    "        self.transition_counts = defaultdict(Counter)\n",
    "\n",
    "    def train(self, sentences):\n",
    "        for sent in sentences:\n",
    "            prev_tag = self.start_symbol\n",
    "            self.tag_counts[prev_tag] += 1\n",
    "\n",
    "            for word, tag in sent:\n",
    "                self.tags.add(tag)\n",
    "                self.words.add(word)\n",
    "\n",
    "                self.tag_counts[tag] += 1\n",
    "                self.emission_counts[tag][word] += 1\n",
    "                self.transition_counts[prev_tag][tag] += 1\n",
    "\n",
    "                prev_tag = tag\n",
    "\n",
    "        self.words.add(self.unk)\n",
    "\n",
    "        # Precompute probabilities\n",
    "        self.emission_probs = {}\n",
    "        for tag in self.tags:\n",
    "            total = sum(self.emission_counts[tag].values())\n",
    "            V = len(self.words)\n",
    "            self.emission_probs[tag] = {}\n",
    "            for w in self.words:\n",
    "                c = self.emission_counts[tag][w]\n",
    "                self.emission_probs[tag][w] = (c + self.smoothing) / (total + self.smoothing * V)\n",
    "\n",
    "        self.transition_probs = {}\n",
    "        for prev in list(self.transition_counts.keys()) + [self.start_symbol]:\n",
    "            self.transition_probs[prev] = {}\n",
    "            total = sum(self.transition_counts[prev].values())\n",
    "            Vt = len(self.tags)\n",
    "            for tag in self.tags:\n",
    "                c = self.transition_counts[prev][tag]\n",
    "                self.transition_probs[prev][tag] = (c + self.smoothing) / (total + self.smoothing * Vt)\n",
    "\n",
    "    def _emission(self, tag, word):\n",
    "        if word not in self.words:\n",
    "            word = self.unk\n",
    "        return self.emission_probs[tag].get(word, 1e-12)\n",
    "\n",
    "    def _transition(self, prev, tag):\n",
    "        return self.transition_probs.get(prev, {}).get(tag, 1e-12)\n",
    "\n",
    "    \n",
    "    # 4. VITERBI DECODING\n",
    "    def viterbi(self, words):\n",
    "        T = len(words)\n",
    "        tags = list(self.tags)\n",
    "\n",
    "        dp = [defaultdict(lambda: -math.inf) for _ in range(T)]\n",
    "        bp = [defaultdict(lambda: None) for _ in range(T)]\n",
    "\n",
    "        # Initialization\n",
    "        for tag in tags:\n",
    "            dp[0][tag] = math.log(self._transition(self.start_symbol, tag)) + \\\n",
    "                         math.log(self._emission(tag, words[0]))\n",
    "\n",
    "        # Recursion\n",
    "        for t in range(1, T):\n",
    "            w = words[t]\n",
    "            for tag in tags:\n",
    "                best_score = -math.inf\n",
    "                best_prev = None\n",
    "\n",
    "                for prev_tag in tags:\n",
    "                    score = dp[t-1][prev_tag] + math.log(self._transition(prev_tag, tag))\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_prev = prev_tag\n",
    "\n",
    "                dp[t][tag] = best_score + math.log(self._emission(tag, w))\n",
    "                bp[t][tag] = best_prev\n",
    "\n",
    "        # Termination\n",
    "        last_tag = max(dp[-1], key=dp[-1].get)\n",
    "\n",
    "        # Backtrack\n",
    "        tags_out = [None] * T\n",
    "        tags_out[-1] = last_tag\n",
    "        for t in range(T-1, 0, -1):\n",
    "            tags_out[t-1] = bp[t][tags_out[t]]\n",
    "\n",
    "        return tags_out\n",
    "\n",
    "\n",
    "# 5. EVALUATION: PRECISION, RECALL, F1\n",
    "\n",
    "def evaluate(gold_sents, pred_sents):\n",
    "    assert len(gold_sents) == len(pred_sents)\n",
    "\n",
    "    counts = defaultdict(lambda: {\"TP\":0, \"FP\":0, \"FN\":0})\n",
    "    tagset = set()\n",
    "\n",
    "    for gold, pred in zip(gold_sents, pred_sents):\n",
    "        for g, p in zip(gold, pred):\n",
    "            tagset.add(g)\n",
    "            tagset.add(p)\n",
    "            if g == p:\n",
    "                counts[g][\"TP\"] += 1\n",
    "            else:\n",
    "                counts[p][\"FP\"] += 1\n",
    "                counts[g][\"FN\"] += 1\n",
    "\n",
    "    per_tag = {}\n",
    "    f1s = []\n",
    "\n",
    "    for tag in sorted(tagset):\n",
    "        TP = counts[tag][\"TP\"]\n",
    "        FP = counts[tag][\"FP\"]\n",
    "        FN = counts[tag][\"FN\"]\n",
    "\n",
    "        prec = TP / (TP + FP) if TP + FP else 0\n",
    "        rec = TP / (TP + FN) if TP + FN else 0\n",
    "        f1 = 2*prec*rec / (prec + rec) if prec + rec else 0\n",
    "\n",
    "        per_tag[tag] = (prec, rec, f1)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    macro_f1 = sum(f1s) / len(f1s)\n",
    "    return per_tag, macro_f1\n",
    "\n",
    "\n",
    "\n",
    "# 6. RUN K-FOLD\n",
    "def run_kfold(k=5):\n",
    "    data = load_tagged_corpus(\"wsj_pos_tagged_en.txt\")\n",
    "    folds = k_fold_split(data, k)\n",
    "\n",
    "    macro_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        print(f\"\\n=== Fold {i+1}/{k} ===\")\n",
    "\n",
    "        test = folds[i]\n",
    "        train = [s for j, fold in enumerate(folds) if j != i for s in fold]\n",
    "\n",
    "        hmm = HMMTagger(smoothing=1.0)\n",
    "        hmm.train(train)\n",
    "\n",
    "        gold_tags = []\n",
    "        pred_tags = []\n",
    "\n",
    "        for sent in test:\n",
    "            words = [w for w, t in sent]\n",
    "            gold = [t for w, t in sent]\n",
    "            pred = hmm.viterbi(words)\n",
    "\n",
    "            gold_tags.append(gold)\n",
    "            pred_tags.append(pred)\n",
    "\n",
    "        per_tag, macro_f1 = evaluate(gold_tags, pred_tags)\n",
    "        print(f\"Macro F1 = {macro_f1:.4f}\")\n",
    "\n",
    "        macro_scores.append(macro_f1)\n",
    "\n",
    "    print(\"\\nAverage Macro F1 Across Folds:\", sum(macro_scores)/k)\n",
    "\n",
    "run_kfold(k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
