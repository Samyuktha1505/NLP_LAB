{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3908a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences loaded: 10000\n",
      "Sample sentence: అమెరికా అధ్యక్షుడు డొనాల్డ్ ట్రంప్ కు రాష్ట్రపతి భవన్ వద్ద ఘనస్వాగతం లభించింది. ఆయనకు రాష్ట్రపతి రామ్ నాథ్ కోవింద్ దంపతులు, ప్రధాని మోదీ సాదరంగా ఆహ్వానం పలకడంతో పాటు సైనికులు గౌరవ వందనాన్ని అందించారు.\n",
      "Train: 8000, Validation: 1000, Test: 1000\n",
      "Counting n-grams...\n",
      "Unique unigrams: 60,951\n",
      "Unique bigrams: 231,960\n",
      "Unique trigrams: 302,928\n",
      "Unique quadrigrams: 326,143\n",
      "Saved unigram.csv\n",
      "Saved bigram.csv\n",
      "Saved trigram.csv\n",
      "Saved quadrigram.csv\n",
      "Sentence probability (Bigram Good-Turing): 0.00000000\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.util import ngrams\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "\n",
    "# =========================\n",
    "# 1. Load Telugu dataset\n",
    "# =========================\n",
    "dataset_path = \"../ASSIGNMENT-1/telugu_dataset.txt\" \n",
    "NLP_LAB= \"./\" \n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_sentences = [line.strip() for line in f if line.strip()]\n",
    "raw_sentences = raw_sentences[:10000]\n",
    "print(f\"Total sentences loaded: {len(raw_sentences)}\")\n",
    "print(\"Sample sentence:\", raw_sentences[0])\n",
    "\n",
    "# =========================\n",
    "# 2. Sentence & word tokenizer\n",
    "# =========================\n",
    "def telugu_sentence_tokenizer(text):\n",
    "    return re.split(r'(?<=[।!?॥.])\\s+', text)\n",
    "\n",
    "def telugu_word_tokenizer(text):\n",
    "    url = r'https?://\\S+'\n",
    "    email = r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b'\n",
    "    date = r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b'\n",
    "    decimal = r'\\b\\d+\\.\\d+\\b'\n",
    "    number = r'\\b\\d+\\b'\n",
    "    telugu = r'[\\u0C00-\\u0C7F]+'\n",
    "    english = r'[a-zA-Z]+'\n",
    "    punctuation = r'[.,!?;:\"(){}\\[\\]<>|/@#$%^&*_+=~`\\'“”‘’₹…-]'\n",
    "    pattern = f'{url}|{email}|{date}|{decimal}|{number}|{telugu}|{english}|{punctuation}'\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "# =========================\n",
    "# 3. Split dataset\n",
    "# =========================\n",
    "random.seed(42)\n",
    "random.shuffle(raw_sentences)\n",
    "val_set = raw_sentences[:1000]\n",
    "test_set = raw_sentences[1000:2000]\n",
    "train_set = raw_sentences[2000:]\n",
    "\n",
    "print(f\"Train: {len(train_set)}, Validation: {len(val_set)}, Test: {len(test_set)}\")\n",
    "\n",
    "# =========================\n",
    "# 4. Count n-grams\n",
    "# =========================\n",
    "def count_ngrams(sentences, n):\n",
    "    counter = Counter()\n",
    "    for sent in sentences:\n",
    "        tokens = telugu_word_tokenizer(sent)\n",
    "        if not tokens:\n",
    "            continue\n",
    "        padded = ['<s>']*(n-1) + tokens + ['</s>']*(n-1)\n",
    "        counter.update(ngrams(padded, n))\n",
    "    return counter\n",
    "\n",
    "print(\"Counting n-grams...\")\n",
    "unigram_counts = count_ngrams(train_set, 1)\n",
    "bigram_counts = count_ngrams(train_set, 2)\n",
    "trigram_counts = count_ngrams(train_set, 3)\n",
    "quadrigram_counts = count_ngrams(train_set, 4)\n",
    "\n",
    "print(f\"Unique unigrams: {len(unigram_counts):,}\")\n",
    "print(f\"Unique bigrams: {len(bigram_counts):,}\")\n",
    "print(f\"Unique trigrams: {len(trigram_counts):,}\")\n",
    "print(f\"Unique quadrigrams: {len(quadrigram_counts):,}\")\n",
    "\n",
    "# =========================\n",
    "# 5. Good-Turing smoothing\n",
    "# =========================\n",
    "def good_turing_probs(ngram_counter, vocab_size, n):\n",
    "    count_of_counts = Counter(ngram_counter.values())\n",
    "    N1 = count_of_counts.get(1, 0)\n",
    "    N = sum(ngram_counter.values())\n",
    "\n",
    "    if n == 1:\n",
    "        unseen_count = vocab_size - len(ngram_counter)\n",
    "    else:\n",
    "        unseen_count = vocab_size ** n - len(ngram_counter)\n",
    "\n",
    "    P_unseen = (N1 / N) / max(unseen_count, 1)\n",
    "    probs = {ng: count / N for ng, count in ngram_counter.items()}\n",
    "    return probs, P_unseen\n",
    "\n",
    "vocab = set(itertools.chain.from_iterable([ng[0] for ng in unigram_counts]))\n",
    "V = len(vocab)\n",
    "\n",
    "unigram_probs, unigram_P_unseen = good_turing_probs(unigram_counts, V, 1)\n",
    "bigram_probs, bigram_P_unseen = good_turing_probs(bigram_counts, V, 2)\n",
    "trigram_probs, trigram_P_unseen = good_turing_probs(trigram_counts, V, 3)\n",
    "quadrigram_probs, quadrigram_P_unseen = good_turing_probs(quadrigram_counts, V, 4)\n",
    "\n",
    "# =========================\n",
    "# 6. Save n-grams to CSV\n",
    "# =========================\n",
    "def save_ngram_csv(filename, ngram_counts, ngram_probs, P_unseen):\n",
    "    with open(filename, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['ngram', 'count', 'MLE_prob', 'GoodTuring_prob', 'P_unseen'])\n",
    "        total_count = sum(ngram_counts.values())\n",
    "        for ng in ngram_counts:\n",
    "            writer.writerow([\n",
    "                ' '.join(ng),\n",
    "                ngram_counts[ng],\n",
    "                ngram_counts[ng]/total_count,\n",
    "                ngram_probs[ng],\n",
    "                P_unseen\n",
    "            ])\n",
    "    print(f\"Saved {filename}\")\n",
    "\n",
    "save_ngram_csv(\"unigram.csv\", unigram_counts, unigram_probs, unigram_P_unseen)\n",
    "save_ngram_csv(\"bigram.csv\", bigram_counts, bigram_probs, bigram_P_unseen)\n",
    "save_ngram_csv(\"trigram.csv\", trigram_counts, trigram_probs, trigram_P_unseen)\n",
    "save_ngram_csv(\"quadrigram.csv\", quadrigram_counts, quadrigram_probs, quadrigram_P_unseen)\n",
    "\n",
    "# =========================\n",
    "# 7. Sentence probability using smoothed n-grams\n",
    "# =========================\n",
    "def sentence_prob(sentence, n, ngram_probs, P_unseen):\n",
    "    tokens = telugu_word_tokenizer(sentence)\n",
    "    padded = ['<s>']*(n-1) + tokens + ['</s>']*(n-1)\n",
    "    ngrams_list = list(ngrams(padded, n))\n",
    "    prob = 1.0\n",
    "    for ng in ngrams_list:\n",
    "        prob *= ngram_probs.get(ng, P_unseen)\n",
    "    return prob\n",
    "\n",
    "# Example usage\n",
    "example_sentence = \"ఈ రోజు వాతావరణం బాగుంది.\"\n",
    "prob_bigram = sentence_prob(example_sentence, 2, bigram_probs, bigram_P_unseen)\n",
    "print(f\"Sentence probability (Bigram Good-Turing): {prob_bigram:.8f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
